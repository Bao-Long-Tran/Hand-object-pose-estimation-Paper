\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{cai20203d,zimmermann2017learning,gao2019variational,xiang2017posecnn,tremblay2018deep}
\citation{oberweger2017deepprior++,moon2018v2v,xiong2019a2j,ge20173d,cai2022ove6d,li2020category}
\citation{kazakos2018fusion,yuan20193d}
\citation{hasson2019learning,hasson2020leveraging,tekin2019h+,tse2022collaborative,liu2021semi,oikonomidis2011full,lu2021understanding,hasson2021towards,wang2020learning}
\citation{choi2017robust,zhang2021single,goudie20173d,oberweger2019generalized}
\citation{kyriazis2013physically,tsoli2018joint}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{\hskip -1em.~Introduction}{section.1}{}}
\@writefile{brf}{\backcite{cai20203d, zimmermann2017learning, gao2019variational, xiang2017posecnn, tremblay2018deep}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{oberweger2017deepprior++, moon2018v2v, xiong2019a2j, ge20173d, cai2022ove6d, li2020category}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{kazakos2018fusion, yuan20193d}{{1}{1}{section.1}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:result_exp}{{\caption@xref {fig:result_exp}{ on input line 9}}{1}{\hskip -1em.~Introduction}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of RGB-D.\relax }}{1}{figure.caption.1}}
\@writefile{brf}{\backcite{hasson2019learning, hasson2020leveraging, tekin2019h+, tse2022collaborative, liu2021semi, oikonomidis2011full, lu2021understanding, hasson2021towards, wang2020learning}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{choi2017robust, zhang2021single, goudie20173d, oberweger2019generalized}{{1}{1}{figure.caption.1}}}
\citation{qi2017pointnet++}
\citation{ding2019votenet}
\citation{wang2019densefusion}
\citation{ding2019votenet,wu2021vote,hoang2022voting}
\citation{yang2022dynamic,madadi2017end,deng2017hand3d,oberweger2017deepprior++,iqbal2018hand}
\citation{wang2019densefusion,schwarz2015rgb,qi2018frustum,zhou2018voxelnet}
\citation{doosti2020hope}
\citation{tse2022collaborative}
\citation{hasson2020leveraging}
\citation{tekin2019h+}
\citation{liu2021semi}
\citation{choi2017robust}
\citation{zhang2021single,goudie20173d}
\citation{oberweger2019generalized}
\citation{kyriazis2013physically}
\citation{tsoli2018joint}
\citation{chen2021global,chen2020bi,park2017rdfnet,zhang2021non}
\citation{wang2019densefusion,tian2020robust,saadi2021optimizing}
\citation{wang2021brief}
\citation{wang2019densefusion}
\citation{qi2017pointnet++}
\@writefile{brf}{\backcite{kyriazis2013physically, tsoli2018joint}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{qi2017pointnet++}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{ding2019votenet}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{wang2019densefusion}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{ding2019votenet, wu2021vote, hoang2022voting}{{2}{1}{figure.caption.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related work}{2}{section.2}}
\newlabel{sec:relatedwork}{{2}{2}{\hskip -1em.~Related work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}Hand-object pose estimation}{2}{subsection.2.1}}
\@writefile{brf}{\backcite{yang2022dynamic, madadi2017end, deng2017hand3d, oberweger2017deepprior++, iqbal2018hand}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{wang2019densefusion, schwarz2015rgb, qi2018frustum, zhou2018voxelnet}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{doosti2020hope}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{tse2022collaborative}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{hasson2020leveraging}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{tekin2019h+}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{liu2021semi}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{choi2017robust}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{zhang2021single, goudie20173d}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{oberweger2019generalized}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{kyriazis2013physically}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{tsoli2018joint}{{2}{2.1}{subsection.2.1}}}
\citation{hough1959machine,duda1972textordfeminineuse}
\citation{silberberg1984iterative,tombari2010object}
\citation{ding2019votenet,kehl2016deep,wu2021vote,hoang2022voting}
\citation{qi2017pointnet}
\citation{qi2017pointnet++}
\citation{romero2022embodied}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}RGB-D fusion}{3}{subsection.2.2}}
\@writefile{brf}{\backcite{chen2021global, chen2020bi, park2017rdfnet, zhang2021non}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{wang2019densefusion, tian2020robust, saadi2021optimizing}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{wang2021brief}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{wang2019densefusion}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{qi2017pointnet++}{{3}{2.2}{subsection.2.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.\nobreakspace  {}Voting mechanism for pose estimation}{3}{subsection.2.3}}
\@writefile{brf}{\backcite{hough1959machine, duda1972textordfeminineuse}{{3}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{silberberg1984iterative, tombari2010object}{{3}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{ding2019votenet, kehl2016deep, wu2021vote, hoang2022voting}{{3}{2.3}{subsection.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Method}{3}{section.3}}
\newlabel{sec:methodology}{{3}{3}{\hskip -1em.~Method}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Attentional Fusion}{3}{subsection.3.1}}
\newlabel{sec:attentional_fusion}{{3.1}{3}{\hskip -1em.~Attentional Fusion}{subsection.3.1}{}}
\@writefile{brf}{\backcite{qi2017pointnet}{{3}{3.1}{figure.caption.3}}}
\@writefile{brf}{\backcite{qi2017pointnet++}{{3}{3.1}{figure.caption.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Hand and Object Voting}{3}{subsection.3.2}}
\newlabel{sec:voting}{{3.2}{3}{\hskip -1em.~Hand and Object Voting}{subsection.3.2}{}}
\@writefile{brf}{\backcite{romero2022embodied}{{3}{3.2}{subsection.3.2}}}
\newlabel{eq:loss_handjoints}{{2}{3}{\hskip -1em.~Hand and Object Voting}{equation.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Overview of our proposal. Our method takes both color and depth maps as input data. The color features are extracted by a CNN, while the 3D features are calculated by PointNet++ architecture. These two types of features are then fused together at pixel-level to obtain the new distinctive features. The attention mechanism is applied for the such new features to learn the contribution disparity of the context to the hand pose. The votes are computed and then regressed to estimate the MANO parameters.\relax }}{4}{figure.caption.2}}
\newlabel{fig:Hand_pose}{{2}{4}{Overview of our proposal. Our method takes both color and depth maps as input data. The color features are extracted by a CNN, while the 3D features are calculated by PointNet++ architecture. These two types of features are then fused together at pixel-level to obtain the new distinctive features. The attention mechanism is applied for the such new features to learn the contribution disparity of the context to the hand pose. The votes are computed and then regressed to estimate the MANO parameters.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Attentional fusion.\relax }}{4}{figure.caption.3}}
\newlabel{fig:attentional_fusion}{{3}{4}{Attentional fusion.\relax }{figure.caption.3}{}}
\newlabel{eq:loss_objectpoints}{{3}{4}{\hskip -1em.~Hand and Object Voting}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Hand and Object Poses Estimation}{4}{subsection.3.3}}
\newlabel{sec:interaction}{{3.3}{4}{\hskip -1em.~Hand and Object Poses Estimation}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Illustration of the interaction learning between votes for hand keypoints and votes for object keypoints. The red points denote hand keypoints, while the yellow ones denote object keypoints. The blue and green vectors represent hand keypoints and object keypoints votes, respectively.\relax }}{4}{figure.caption.4}}
\bibstyle{ieee_fullname}
\bibdata{egbib}
\bibcite{cai2022ove6d}{1}
\bibcite{cai20203d}{2}
\bibcite{chen2021global}{3}
\bibcite{chen2020bi}{4}
\bibcite{choi2017robust}{5}
\bibcite{deng2017hand3d}{6}
\bibcite{ding2019votenet}{7}
\bibcite{doosti2020hope}{8}
\bibcite{duda1972textordfeminineuse}{9}
\bibcite{gao2019variational}{10}
\bibcite{ge20173d}{11}
\bibcite{goudie20173d}{12}
\bibcite{hasson2020leveraging}{13}
\newlabel{eq:edge_feature}{{4}{5}{\hskip -1em.~Hand and Object Poses Estimation}{equation.3.4}{}}
\newlabel{eq:loss_handpose}{{5}{5}{\hskip -1em.~Hand and Object Poses Estimation}{equation.3.5}{}}
\newlabel{eq:loss_handpose}{{6}{5}{\hskip -1em.~Hand and Object Poses Estimation}{equation.3.6}{}}
\newlabel{eq:hand-object}{{8}{5}{\hskip -1em.~Hand and Object Poses Estimation}{equation.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Evaluation}{5}{section.4}}
\newlabel{sec:Eval }{{4}{5}{\hskip -1em.~Evaluation}{section.4}{}}
\bibcite{hasson2021towards}{14}
\bibcite{hasson2019learning}{15}
\bibcite{hoang2022voting}{16}
\bibcite{hough1959machine}{17}
\bibcite{iqbal2018hand}{18}
\bibcite{kazakos2018fusion}{19}
\bibcite{kehl2016deep}{20}
\bibcite{kyriazis2013physically}{21}
\bibcite{li2020category}{22}
\bibcite{liu2021semi}{23}
\bibcite{lu2021understanding}{24}
\bibcite{madadi2017end}{25}
\bibcite{moon2018v2v}{26}
\bibcite{oberweger2017deepprior++}{27}
\bibcite{oberweger2019generalized}{28}
\bibcite{oikonomidis2011full}{29}
\bibcite{park2017rdfnet}{30}
\bibcite{qi2018frustum}{31}
\bibcite{qi2017pointnet++}{32}
\bibcite{romero2022embodied}{33}
\bibcite{saadi2021optimizing}{34}
\bibcite{schwarz2015rgb}{35}
\bibcite{silberberg1984iterative}{36}
\bibcite{tekin2019h+}{37}
\bibcite{tian2020robust}{38}
\bibcite{tombari2010object}{39}
\bibcite{tremblay2018deep}{40}
\bibcite{tse2022collaborative}{41}
\bibcite{tsoli2018joint}{42}
\bibcite{wang2021brief}{43}
\bibcite{wang2019densefusion}{44}
\bibcite{wang2020learning}{45}
\bibcite{wu2021vote}{46}
\bibcite{xiang2017posecnn}{47}
\bibcite{xiong2019a2j}{48}
\bibcite{yang2022dynamic}{49}
\bibcite{yuan20193d}{50}
\bibcite{zhang2021non}{51}
\bibcite{zhang2021single}{52}
\bibcite{zhou2018voxelnet}{53}
\bibcite{zimmermann2017learning}{54}
